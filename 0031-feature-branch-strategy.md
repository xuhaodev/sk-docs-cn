
# 社区驱动的连接器和功能策略

## 上下文和问题陈述

通常，连接器是中等到复杂的新功能，可以由一个人或一个团队开发。为了避免冲突并更好地控制开发过程，我们强烈建议在我们的仓库中使用 Feature Branch Strategy。

在我们当前的软件开发过程中，管理主分支中的更改变得越来越复杂，从而导致发布周期的潜在冲突和延迟。

## 标准和准则原则

- **模式**：Feature Branch Strategy 是一种众所周知的模式，用于管理代码库中的更改。它在行业中得到广泛应用，并得到包括 GitHub 在内的大多数版本控制系统的支持，这也进一步清楚地说明了社区如何为 SK 的连接器或任何其他更大功能的开发做出有意义的贡献。
- **隔离的开发环境**：通过使用功能分支，每个开发人员都可以在不干扰他人工作的情况下处理项目的不同方面。这种隔离减少了冲突并确保 main 分支保持稳定。
- **简化的集成**：功能分支简化了将新代码集成到主分支的过程。通过处理更小、更易于管理的更改，可以最大限度地降低集成过程中发生重大冲突的风险。
- **代码审查的效率**：功能分支中更小、更集中的更改会带来更快、更高效的代码审查。这种效率不仅与一次审查较少代码的便利性有关，还与了解更改的上下文和影响所节省的时间有关。
- **降低 Bug 风险**：隔离功能分支中的开发可降低将 Bug 引入 main 分支的可能性。在单个功能的有限上下文中识别和修复问题更容易。
- **及时的功能集成**：小型、增量的拉取请求可以更快地审查和更快地将功能集成到功能分支中，并且更容易合并到 main 中，因为代码之前已经经过审查。这种及时性可确保功能更快地合并并准备好部署，从而提高对更改的响应能力。
- **代码测试、覆盖率和质量**：为了保持良好的代码质量，必须对引入代码库的任何新代码或功能进行适当的测试和验证。任何新功能或代码都应该包含在单元测试和集成测试中。代码还应由我们的 CI/CD 管道进行验证，并遵循我们的代码质量标准和指南。
- **示例**：任何新功能或代码都应附有演示如何使用新功能或代码的示例。这对于确保新功能或代码被正确记录以及社区可以轻松理解和使用它非常重要。
- **签名**：任何最终将成为包的连接器都需要在文件中启用包和程序集签名（设置为“发布 = 发布”）。 `SK-dotnet.sln` 
  ```
  {Project GUID}.Publish|Any CPU.ActiveCfg = Publish|Any CPU
  {Project GUID}.Publish|Any CPU.Build.0 = Publish|Any CPU
  ```

### 社区功能分支策略

一旦我们确定贡献者愿意将/创建功能问题作为潜在的连接器实现，我们将为该功能创建一个新分支。

一旦我们同意采用新的连接器，我们将与贡献者合作，以确保实施进展并在需要时得到支持。

然后，贡献者将成为负责者之一，在我们的监督和审查流程下，通过小型拉取请求将大部分更改逐步添加到功能分支。

此策略涉及在存储库中为每个新的重要功能（如连接器）创建一个单独的分支。这种隔离意味着在受控环境中进行更改，而不会影响主分支。

我们还可能在需要时参与功能分支的开发和更改，PR 的更改和完整或合著将被跟踪并适当地引用到发行说明中。

#### 优点和缺点

- 很好，因为它允许一次专注于一个功能。
- 很好，因为它促进了更小的增量拉取请求 （PR），从而简化了审查流程。
- 很好，因为它降低了将重大 bug 合并到 main 分支的风险。
- 很好，因为它使将功能集成到 main 分支的过程更容易、更快速。
- 如果管理不当，可能会很糟糕，因为如果不定期与 main 分支同步，它可能会导致分支过时。

## 本地部署平台 / 离线

### LM 工作室

LM Studio 具有本地部署选项，可用于在本地部署模型。此选项适用于 Windows、Linux 和 MacOS。

优点：

- API 与 OpenAI API 非常相似
- 已支持许多模型
- 易于使用
- 易于部署
- GPU 支持

缺点：

- 可能需要许可证才能在工作环境中使用

### 奥拉马

Ollama 有一个本地部署选项，可用于在本地部署模型。此选项目前仅适用于 Linux 和 MacOS。

优点：

- 易于使用
- 易于部署
- 支持 Docker 部署
- GPU 支持

缺点：

- API 与 OpenAI API 不同（需要专用连接器）
- 不支持 Windows

### 比较

| 特征               | 奥拉马                                              | LM 工作室                                                                               |
| --------------------- | --------------------------------------------------- | --------------------------------------------------------------------------------------- |
| 本地法学硕士             | 是的                                                 | 是的                                                                                     |
| OpenAI API 相似性 | 是的                                                 | 是的                                                                                     |
| Windows 支持       | 不                                                  | 是的                                                                                     |
| Linux 支持         | 是的                                                 | 是的                                                                                     |
| MacOS 支持         | 是的                                                 | 是的                                                                                     |
| 型号数量      | [61](https://ollama.com/search) +任何 GGUF 转换 | [25](https://github.com/lmstudio-ai/model-catalog/tree/main/models) +任何 GGUF 转换 |

| 模型支持   | 奥拉马 | LM 工作室 |
| --------------- | ------ | --------- |
| Phi-2 支持   | 是的    | 是的       |
| Llama-2 支持 | 是的    | 是的       |
| Mistral 支持 | 是的    | 是的       |

## 连接器/型号优先级

目前，我们正在寻找以下型号的社区支持

以下支持可以通过以下方式实现：使用现有连接器之一针对此模型之一创建一个实际示例，或者提供支持托管以下模型之一的部署平台的新连接器：

| 型号名称 | 本地支持 | 部署                             | 连接                                             |
| ---------- | ------------- | -------------------------------------- | ------------------------------------------------------ |
| GPT-4      | 不            | OpenAI、Azure                          | Azure+OpenAI                                           |
| Phi-2 （英文）      | 是的           | Azure， Hugging Face， LM Studio， Ollama | OpenAI， HuggingFace， LM Studio\*\*\*， Ollama\*\*       |
| 双子座     | 不            | 谷歌 AI 平台                     | GoogleAI\*\*                                           |
| 骆驼-2    | 是的           | Azure、LM Studio、HuggingFace、Ollama  | HuggingFace， Azure+OpenAI， LM Studio\*\*\*， Ollama\*\* |
| 米斯特拉尔    | 是的           | Azure、LM Studio、HuggingFace、Ollama  | HuggingFace， Azure+OpenAI， LM Studio\*\*\*， Ollama\*\* |
| 克劳德     | 不            | 人类学， 亚马逊基岩              | Anthropic**、亚马逊**                                  |
| 巨人      | 不            | 亚马逊基岩版                         | 亚马逊河\*\*                                             |

_\*\* 连接器尚未提供_

_可能不需要，因为可以使用 OpenAI 连接器_

连接器可能不是按型号需要，而是按部署平台需要。
例如，使用 OpenAI 或 HuggingFace 连接器，您可以调用 Phi-2 模型。

## 预期要实施的连接器

任何连接器尚不支持以下部署平台，我们强烈建议社区参与并支持这些平台：

目前，优先级是有序的，但不一定需要按顺序实现，一个

| 部署平台 | 本地模型支持 |
| ------------------- | ------------------- |
| 奥拉马              | 是的                 |
| 谷歌人工智能            | 不                  |
| 人           | 不                  |
| 亚马逊河              | 不                  |

## 决策结果

选择的选项：“Feature Branch Strategy”，因为它允许单独开发单个功能，最大限度地减少与主分支的冲突，并促进更轻松的代码审查。

## Fequent 常见问题

### 对于遵循旧的分叉贡献方式，现在必须切换到 microsoft/semantic-kernel 中的分支的计划，是否有迁移策略？

您正常进行 fork 和 PR targeting `main`，一旦我们确定您对 main 的贡献 PR 是一个重要且理想的功能（看看我们在此 ADR 中按预期描述的那些），我们将创建一个专用的功能分支 （） ），`feature-yourfeature`您可以在其中重新定位我们的 fork PR 以定位它。
所有进一步的增量更改和贡献都将照常进行，但 `main` 您将以分支为目标 `feature-*` 。

### 您希望如何解决 “up to date with main branch” 问题？

当我们都同意当前功能实现已完成并准备好合并时，就会发生这种情况 `main`。

功能完成后，将从 main 的合并推送到功能分支中。
这通常会触发需要排序的冲突。
这通常是针对功能分支的最后一个 PR，紧随其后的是来自 `feature` 分支的另一个 PR，目标 `main` 冲突最小（如果有）。
合并到 main 可能很快（因为所有中间功能 PR 之前都已达成一致和批准）

### 将 main 分支合并到 feature branch before finish 功能

将 main 分支合并到功能分支只能使用以下命令完成：

`git checkout <feature branch> && git merge main` 不带 --squash

PR 永远不应该从 main 合并到功能分支，这会导致 main 合并历史与 PR 历史（因为 PR 是用 --squash 合并的），因此会在后续的 main 合并中产生奇怪的冲突，也使得分析功能分支的历史变得困难。
